import pyrealsense2 as rs
import numpy as np
import cv2
import time
import os

def capture_rgb_frames_with_timestamp(duration=60):
    # Get the current timestamp for the output directory
    start_time = time.time()
    timestamp = time.strftime("%Y%m%d_%H%M%S", time.localtime(start_time))
    output_dir = f"./data/{timestamp}"

    # Ensure the output directory exists
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Configure depth and color streams
    pipeline = rs.pipeline()
    config = rs.config()

    # Get device product line for setting a supporting resolution
    pipeline_wrapper = rs.pipeline_wrapper(pipeline)
    pipeline_profile = config.resolve(pipeline_wrapper)
    device = pipeline_profile.get_device()
    device_product_line = str(device.get_info(rs.camera_info.product_line))

    found_rgb_stream = False
    for s in device.sensors:
        if s.get_info(rs.camera_info.name) == 'RGB Camera':
            found_rgb_stream = True
            break

    if not found_rgb_stream:
        print("The connected RealSense camera does not have an RGB stream!")
        return

    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)

    try:
        # Start streaming
        pipeline.start(config)

        frame_count = 0
        while time.time() - start_time < duration:
            # Wait for a coherent pair of frames: depth and color
            frames = pipeline.wait_for_frames(timeout_ms=5000)
            color_frame = frames.get_color_frame()

            if not color_frame:
                continue

            # Convert images to numpy arrays
            color_image = np.asanyarray(color_frame.get_data())

            # Get current timestamp with milliseconds
            current_time = time.strftime("%Y%m%d_%H%M%S", time.localtime())
            milliseconds = int(round(time.time() * 1000)) % 1000
            frame_filename = f"frame_{current_time}_{milliseconds:03d}_{frame_count:04d}.png"
            frame_path = os.path.join(output_dir, frame_filename)

            # Save the image to a file
            cv2.imwrite(frame_path, color_image)
            print(f"Image saved as {frame_path}")

            frame_count += 1

        print(f"Captured {frame_count} frames")

    except RuntimeError as e:
        print(f"RuntimeError: {e}")
    except Exception as e:
        print(f"An error occurred: {e}")
    finally:
        # Stop streaming
        pipeline.stop()

if __name__ == "__main__":
    capture_rgb_frames_with_timestamp(duration=60)  # Capture for 60 seconds



