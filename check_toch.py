import torch

def print_divider(title):
    print("\n" + "="*50)
    print(f" {title} ")
    print("="*50)

# 1. åŸºç¡€ä¿¡æ¯æ£€æµ‹
print_divider("1. PyTorch åŸºç¡€ä¿¡æ¯")
print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda if torch.cuda.is_available() else 'N/A'}")

# 2. CUDA å¯ç”¨æ€§æ£€æµ‹
print_divider("2. CUDA å¯ç”¨æ€§æ£€æµ‹")
if torch.cuda.is_available():
    print("âœ… CUDA å¯ç”¨")
    print(f"å½“å‰è®¾å¤‡: {torch.cuda.current_device()}")
    print(f"è®¾å¤‡åç§°: {torch.cuda.get_device_name(0)}")
    print(f"è®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
    
    # CUDAåŠŸèƒ½æµ‹è¯•
    print("\nğŸ”§ CUDA åŠŸèƒ½æµ‹è¯•...")
    try:
        a = torch.tensor([1.0, 2.0, 3.0]).cuda()
        b = torch.tensor([4.0, 5.0, 6.0]).cuda()
        c = a + b
        print("âœ… CUDA å¼ é‡è®¡ç®—æˆåŠŸ")
        print(f"è®¡ç®—ç»“æœ: {c.cpu().numpy()}")
    except Exception as e:
        print(f"âŒ CUDA æµ‹è¯•å¤±è´¥: {str(e)}")
else:
    print("âŒ CUDA ä¸å¯ç”¨")
    print("æç¤º: è¯·æ£€æŸ¥æ˜¯å¦æ­£ç¡®å®‰è£…CUDA PyTorchç‰ˆæœ¬")

# 3. cuDNN æ£€æµ‹
print_divider("3. cuDNN åŠŸèƒ½æ£€æµ‹")
if torch.cuda.is_available():
    # ä½¿ç”¨å·ç§¯æ“ä½œæµ‹è¯•cuDNN
    print("ğŸ”§ è¿è¡ŒcuDNNå·ç§¯æµ‹è¯•...")
    try:
        # åˆ›å»ºéšæœºçš„è¾“å…¥å’Œå·ç§¯æ ¸
        input = torch.randn(1, 3, 32, 32).cuda()
        conv = torch.nn.Conv2d(3, 6, 3).cuda()
        output = conv(input)
        
        print(f"âœ… cuDNN å·ç§¯è¿ç®—æˆåŠŸ")
        print(f"è¾“å‡ºç»´åº¦: {output.shape}")
        
        # æ£€æµ‹cuDNNç‰ˆæœ¬
        if torch.backends.cudnn.enabled:
            print(f"cuDNN ç‰ˆæœ¬: v{torch.backends.cudnn.version()}")
        else:
            print("âš ï¸ cuDNN å·²å®‰è£…ä½†æœªå¯ç”¨")
            
    except Exception as e:
        print(f"âŒ cuDNN æµ‹è¯•å¤±è´¥: {str(e)}")
        print("æç¤º: è¯·æ£€æŸ¥cuDNNä¸CUDAç‰ˆæœ¬çš„å…¼å®¹æ€§")
else:
    print("â© è·³è¿‡cuDNNæµ‹è¯• (CUDAä¸å¯ç”¨)")

# 4. è®¾å¤‡æ€§èƒ½åŸºå‡†æµ‹è¯•
print_divider("4. GPU æ€§èƒ½åŸºå‡†æµ‹è¯•")
if torch.cuda.is_available():
    print("â±ï¸ è¿è¡ŒçŸ©é˜µä¹˜æ³•åŸºå‡†æµ‹è¯•...")
    try:
        device = torch.device("cuda")
        x = torch.rand(10000, 10000, device=device)
        y = torch.rand(10000, 10000, device=device)
        
        # é¢„çƒ­
        torch.cuda.synchronize()
        torch.matmul(x, y)
        torch.cuda.synchronize()
        
        # æ­£å¼æµ‹è¯•
        import time
        start = time.time()
        torch.matmul(x, y)
        torch.cuda.synchronize()
        duration = time.time() - start
        
        print(f"âœ… GPU è®¡ç®—å®Œæˆ (è€—æ—¶: {duration:.4f}ç§’)")
        print(f"é¢„è®¡æ€§èƒ½: {1e9/(duration):.0f} FLOPS")
    except Exception as e:
        print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
else:
    print("â© è·³è¿‡æ€§èƒ½æµ‹è¯• (CUDAä¸å¯ç”¨)")

print_divider("æµ‹è¯•å®Œæˆ")
print(f"æœ€ç»ˆçŠ¶æ€: {'âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡' if torch.cuda.is_available() else 'âŒ å­˜åœ¨æœªé€šè¿‡çš„æµ‹è¯•'}")
